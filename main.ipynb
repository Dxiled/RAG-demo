{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d08a6f3",
   "metadata": {},
   "source": [
    "# PDF RAG with context highlighting\n",
    "\n",
    "This notebook is a demonstration of retrieval augmented generation with context highlighting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67059126",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "Install and import dependancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf\n",
    "!pip install langchain\n",
    "!pip install transformers\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff843b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pdf tools\n",
    "import fitz\n",
    "\n",
    "# Langchain modules\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41044780",
   "metadata": {},
   "source": [
    "## Load the context document\n",
    "\n",
    "Change the `doc_path` to locate the source document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22abef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"insurance_sample.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14700eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF tool\n",
    "doc = fitz.open(doc_path)\n",
    "\n",
    "# Extract the text manually using blocks\n",
    "texts = []\n",
    "for page in doc:\n",
    "    blocks = page.get_text(\"blocks\")\n",
    "    for block in blocks:\n",
    "        page_num = page.number\n",
    "        author = doc.metadata['author'] if 'author' in doc.metadata else \"\"\n",
    "        text = Document(\n",
    "            page_content = block[4],\n",
    "            metadata = {\n",
    "                'source':doc_path,\n",
    "                'page':page_num,\n",
    "                'author':author\n",
    "            }\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "# Embed the extracted text and store in a ChromaDB\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large\")\n",
    "retriever = Chroma.from_documents(texts, embeddings).as_retriever(search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3f545",
   "metadata": {},
   "source": [
    "## Prepare the LLM pipeline\n",
    "\n",
    "Change the `model_name` to select an open LLM from the HuggingFace leaderboards. I am using `facebook/opt-iml-max-1.3b`, the top ~1B model at the time of writing, because of hardware limitations.\n",
    "\n",
    "Generally, 7B or 13B models are ideal for RAG. This is only a demonstration, so the LLM's response may not be ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97cbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"facebook/opt-iml-max-1.3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88557cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_name,\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_length\":2048\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bcb300",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "\n",
    "Running the chain produces an `LLMResponse` object, which contains both the LLM's answer based on the context, and the source blocks which we can use for context highlighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71c2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"In what cases would this policy be terminated?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6602b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' (a) nonpayment of premium; (b) nonrenewal by us; (c) nonrenewal by you; (d) nonrenewal by us; (e) nonrenewal by you; (f) nonrenewal by us; (g) nonrenewal by you; (h) intentional loss; (i) intentional loss; (j) nonrenewal by you; (k) nonrenewal by you; (l) nonrenewal by you; (m) nonrenewal by you; (n) nonrenewal by you; (o) nonrenewal by you; (p) nonrenewal by you; (q) nonrenewal by you; (r) nonrenewal by you; (s) nonrenewal by you; (t) nonrenewal by you; (u) nonrenewal by you; (v) nonrenewal by you; (w) nonrenewal by you; (x) nonrenewal by you; (y) nonrenewal by you; (z) nonrenewal by you; (2) nonrenewal by you; (3) nonrenewal by you; (4) nonrenewal by you; (5) nonrenewal by you; (6) nonrenewal by you; (7) nonrenewal by you; (8) nonrenewal by you; (9) nonrenewal by you; (10) nonrenewal by you; (11) nonrenewal by you; (12) nonrenewal by you; (13) nonrenewal by you; (14) nonrenewal by you; (15) nonrenewal by you; (16) nonrenewal by you; (17) nonrenewal by you; (18) nonrenewal by you; (19) nonrenewal by you; (20) nonrenewal by you; (21) nonrenewal by you; (22) nonrenewal by you; (23) nonrenewal by you; (24) nonrenewal by you; (25) nonrenewal by you; (26) nonrenewal by you; (27) nonrenewal by you; (28) nonrenewal by you; (29) nonrenewal by you; (30) nonrenewal by you; (31) nonrenewal by you; (32) nonrenewal by you; (33) nonrenewal by you; (34) nonrenewal by you; (35) nonrenewal by you; (36) nonrenewal by you; (37) nonrenewal by you; (38) nonrenewal by you; (39) nonrenewal by you; (40) nonrenewal by you; (41) nonrenewal by you; (42) nonrenewal by you; (43) nonrenewal by you; (44) nonrenewal by you; (45) nonrenewal by you; (46)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = chain(question)\n",
    "# Display the LLM's answer\n",
    "llm_response['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50855e",
   "metadata": {},
   "source": [
    "## Build a highlighted results PDF\n",
    "\n",
    "Using the PyMuPDF library (imported as fitz) to highlight the source document based on the sources from the `LLMResponse`. Change the `report_path` to locate the destination for the PDF report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc388b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = 'report.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d98425",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = llm_response['source_documents']\n",
    "source_texts = []\n",
    "for source in sources:\n",
    "    source_texts.append(source.page_content)\n",
    "\n",
    "for page in doc:\n",
    "    blocks = page.get_text(\"blocks\")\n",
    "    highlight_quads = []\n",
    "    for block in blocks:\n",
    "        if block[4] in source_texts:\n",
    "            x0 = block[0]\n",
    "            y0 = block[1]\n",
    "            x1 = block[2]\n",
    "            y1 = block[3]\n",
    "            quad = fitz.Quad(\n",
    "                (x0, y0),\n",
    "                (x1, y0),\n",
    "                (x0, y1),\n",
    "                (x1, y1)\n",
    "            )\n",
    "            highlight_quads.append(quad)\n",
    "    \n",
    "    if highlight_quads:\n",
    "        page.add_highlight_annot(highlight_quads)\n",
    "\n",
    "doc.save(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b2d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
